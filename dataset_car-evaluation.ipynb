{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[FUENTE DE INFORMACION: - url: (https://archive.ics.uci.edu/ml/datasets/car+evaluation)](https://archive.ics.uci.edu/ml/datasets/car+evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Indice'></a>\n",
    "## Índice\n",
    "[Inicio ▲](#Indice)\n",
    "1. [Estudiando el conjunto de Datos](#estudiando-los-datos)\n",
    "    1. [Graficando las clases](#grafico-clases)\n",
    "1. [Aplicando SMOTE](#aplicando-smote)\n",
    "    1. [Aplicando SMOTE con las proportions modificadas](#aplicando-smote-proportion)\n",
    "        1. [Matriz de Confusion](#smote-matriz_confusion)\n",
    "    1. [SMOTE IPF con proportion modificado](#smote-ipf-proportion0.7)\n",
    "        1. [Matriz de Confusion](#smote_ipf-matriz_confusion)\n",
    "    1. [SMOTE ENN con proportion modificado](#smote-enn-proportion0.7)\n",
    "        1. [Matriz de Confusion](#smote_enn-matriz_confusion)\n",
    "    1. [SMOTE TOMEKLinks con proportion modificado](#smote-tomekLinks-proportion0.7)\n",
    "        1. [Matriz de Confusion](#smote_tklinks-matriz_confusion)\n",
    "    1. [Analisis SMOTE: Mejor estimador](#analisis-smote-mejor_estimador)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='estudiando-los-datos'></a>\n",
    "## Estudiando el conjunto de Datos\n",
    "[Inicio ▲](#Indice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import category_encoders as ce \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atributo: maint con Niveles : ['vhigh' 'high' 'med' 'low'] \n",
      "Atributo: doors con Niveles : ['2' '3' '4' '5more'] \n",
      "Atributo: persons con Niveles : ['2' '4' 'more'] \n",
      "Atributo: lug_boot con Niveles : ['small' 'med' 'big'] \n",
      "Atributo: safety con Niveles : ['low' 'med' 'high'] \n",
      "Atributo: class con Niveles : [0 1] \n",
      "1    432\n",
      "2    432\n",
      "3    432\n",
      "4    432\n",
      "Name: buying, dtype: int64\n",
      "1    432\n",
      "2    432\n",
      "3    432\n",
      "4    432\n",
      "Name: maint, dtype: int64\n",
      "1    432\n",
      "2    432\n",
      "3    432\n",
      "4    432\n",
      "Name: doors, dtype: int64\n",
      "1    576\n",
      "2    576\n",
      "3    576\n",
      "Name: persons, dtype: int64\n",
      "1    576\n",
      "2    576\n",
      "3    576\n",
      "Name: lug_boot, dtype: int64\n",
      "1    576\n",
      "2    576\n",
      "3    576\n",
      "Name: safety, dtype: int64\n",
      "0    1210\n",
      "1     518\n",
      "Name: class, dtype: int64\n",
      "(1157, 6)\n",
      "(571, 6)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"car_evaluation.csv\",header=None)\n",
    "data.head()\n",
    "col_names = ['buying','maint','doors','persons','lug_boot','safety','class']\n",
    "data.columns = col_names\n",
    "# de la columna de clases se opto por reducir a valores de aceptable e inaceptable, y transformarlos a 0 y 1 respectivamente\n",
    "data=data.replace({\"unacc\":0,\"acc\":1, \"good\":1, \"vgood\":1})\n",
    "def show(data):\n",
    "  for i in data.columns[1:]:\n",
    "    print(\"Atributo: {} con Niveles : {} \".format(i,data[i].unique()))\n",
    "\n",
    "show(data)\n",
    "data.dtypes\n",
    "# Convertimos las variables Categoricas a Ordinales \n",
    "encoder = ce.OrdinalEncoder(cols = ['buying','maint','doors','persons','lug_boot','safety'])\n",
    "data = encoder.fit_transform(data)\n",
    "data.head()\n",
    "for col in col_names:\n",
    "    print(data[col].value_counts())  \n",
    "data.isnull().sum()\n",
    "data['class'].value_counts()\n",
    "X = data.drop(['class'], axis=1)\n",
    "\n",
    "y = data['class']\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.33, random_state=42)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inaceptable: 1210\n",
      "aceptable: 518\n"
     ]
    }
   ],
   "source": [
    "print(\"inaceptable: {}\".format(len(y[y==0])))\n",
    "print(\"aceptable: {}\".format(len(y[y==1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1728 entries, 0 to 1727\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype\n",
      "---  ------    --------------  -----\n",
      " 0   buying    1728 non-null   int32\n",
      " 1   maint     1728 non-null   int32\n",
      " 2   doors     1728 non-null   int32\n",
      " 3   persons   1728 non-null   int32\n",
      " 4   lug_boot  1728 non-null   int32\n",
      " 5   safety    1728 non-null   int32\n",
      " 6   class     1728 non-null   int64\n",
      "dtypes: int32(6), int64(1)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.882661996497373"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clasifier = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "clasifier= GaussianNB()\n",
    "# fit the model\n",
    "\n",
    "clasifier.fit(X_train,y_train)\n",
    "y_pred=clasifier.predict(X_test)\n",
    "clasifier.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "\n",
      " [[381  16]\n",
      " [ 51 123]]\n",
      "Calculo del F1 Score es:  0.7859424920127795\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print('Confusion matrix\\n\\n', cm)\n",
    "\n",
    "def calculoF1_score(cm):\n",
    "    TP = cm[1,1]\n",
    "    TN = cm[0,0]\n",
    "    FP = cm[0,1]\n",
    "    FN = cm[1,0]\n",
    "    return (2*TP)/((2*TP)+FP+FN)\n",
    "\n",
    "print('Calculo del F1 Score es: ', calculoF1_score(cm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='aplicando-smote'></a>\n",
    "## Aplicando SMOTE\n",
    "[Inicio ▲](#Indice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import smote_variants as sv\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-28 11:22:33,777:INFO:SMOTE_TomekLinks: Running sampling via ('SMOTE_TomekLinks', \"{'proportion': 1.0, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': None}\")\n",
      "2022-09-28 11:22:33,778:INFO:SMOTE: Running sampling via ('SMOTE', \"{'proportion': 1.0, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': <module 'numpy.random' from 'C:\\\\\\\\Users\\\\\\\\FamiliaNatelloMedina\\\\\\\\AppData\\\\\\\\Roaming\\\\\\\\Python\\\\\\\\Python310\\\\\\\\site-packages\\\\\\\\numpy\\\\\\\\random\\\\\\\\__init__.py'>}\")\n",
      "2022-09-28 11:22:33,783:INFO:TomekLinkRemoval: Running noise removal via TomekLinkRemoval\n",
      "2022-09-28 11:22:33,817:INFO:distance_SMOTE: Running sampling via ('distance_SMOTE', \"{'proportion': 0.2, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': None}\")\n",
      "2022-09-28 11:22:33,843:INFO:distance_SMOTE: Running sampling via ('distance_SMOTE', \"{'proportion': 0.2, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': None}\")\n",
      "2022-09-28 11:22:33,873:INFO:distance_SMOTE: Running sampling via ('distance_SMOTE', \"{'proportion': 0.2, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': None}\")\n",
      "2022-09-28 11:22:33,897:INFO:distance_SMOTE: Running sampling via ('distance_SMOTE', \"{'proportion': 0.3, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': None}\")\n",
      "2022-09-28 11:22:33,922:INFO:distance_SMOTE: Running sampling via ('distance_SMOTE', \"{'proportion': 0.3, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': None}\")\n",
      "2022-09-28 11:22:33,942:INFO:distance_SMOTE: Running sampling via ('distance_SMOTE', \"{'proportion': 0.3, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': None}\")\n",
      "2022-09-28 11:22:33,968:INFO:distance_SMOTE: Running sampling via ('distance_SMOTE', \"{'proportion': 0.4, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': None}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:1157\n",
      "y_train:1157\n",
      "X_test:571\n",
      "y_test:571\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[CV] END clf__oversampler=('distance_SMOTE', \"{'proportion': 0.2, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': None}\"); total time=   0.0s\n",
      "[CV] END clf__oversampler=('distance_SMOTE', \"{'proportion': 0.2, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': None}\"); total time=   0.0s\n",
      "[CV] END clf__oversampler=('distance_SMOTE', \"{'proportion': 0.2, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': None}\"); total time=   0.0s\n",
      "[CV] END clf__oversampler=('distance_SMOTE', \"{'proportion': 0.3, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': None}\"); total time=   0.0s\n",
      "[CV] END clf__oversampler=('distance_SMOTE', \"{'proportion': 0.3, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': None}\"); total time=   0.0s\n",
      "[CV] END clf__oversampler=('distance_SMOTE', \"{'proportion': 0.3, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': None}\"); total time=   0.0s\n",
      "[CV] END clf__oversampler=('distance_SMOTE', \"{'proportion': 0.4, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': None}\"); total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-28 11:22:33,998:INFO:distance_SMOTE: Running sampling via ('distance_SMOTE', \"{'proportion': 0.4, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': None}\")\n",
      "2022-09-28 11:22:34,021:INFO:distance_SMOTE: Running sampling via ('distance_SMOTE', \"{'proportion': 0.4, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': None}\")\n",
      "2022-09-28 11:22:34,043:INFO:distance_SMOTE: Running sampling via ('distance_SMOTE', \"{'proportion': 0.5, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': None}\")\n",
      "2022-09-28 11:22:34,063:INFO:distance_SMOTE: Running sampling via ('distance_SMOTE', \"{'proportion': 0.5, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': None}\")\n",
      "2022-09-28 11:22:34,085:INFO:distance_SMOTE: Running sampling via ('distance_SMOTE', \"{'proportion': 0.5, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': None}\")\n",
      "2022-09-28 11:22:34,105:INFO:distance_SMOTE: Running sampling via ('distance_SMOTE', \"{'proportion': 0.6, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': None}\")\n",
      "2022-09-28 11:22:34,125:INFO:distance_SMOTE: Running sampling via ('distance_SMOTE', \"{'proportion': 0.6, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': None}\")\n",
      "2022-09-28 11:22:34,146:INFO:distance_SMOTE: Running sampling via ('distance_SMOTE', \"{'proportion': 0.6, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': None}\")\n",
      "2022-09-28 11:22:34,170:INFO:distance_SMOTE: Running sampling via ('distance_SMOTE', \"{'proportion': 0.7, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': None}\")\n",
      "2022-09-28 11:22:34,190:INFO:distance_SMOTE: Running sampling via ('distance_SMOTE', \"{'proportion': 0.7, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': None}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__oversampler=('distance_SMOTE', \"{'proportion': 0.4, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': None}\"); total time=   0.0s\n",
      "[CV] END clf__oversampler=('distance_SMOTE', \"{'proportion': 0.4, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': None}\"); total time=   0.0s\n",
      "[CV] END clf__oversampler=('distance_SMOTE', \"{'proportion': 0.5, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': None}\"); total time=   0.0s\n",
      "[CV] END clf__oversampler=('distance_SMOTE', \"{'proportion': 0.5, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': None}\"); total time=   0.0s\n",
      "[CV] END clf__oversampler=('distance_SMOTE', \"{'proportion': 0.5, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': None}\"); total time=   0.0s\n",
      "[CV] END clf__oversampler=('distance_SMOTE', \"{'proportion': 0.6, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': None}\"); total time=   0.0s\n",
      "[CV] END clf__oversampler=('distance_SMOTE', \"{'proportion': 0.6, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': None}\"); total time=   0.0s\n",
      "[CV] END clf__oversampler=('distance_SMOTE', \"{'proportion': 0.6, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': None}\"); total time=   0.0s\n",
      "[CV] END clf__oversampler=('distance_SMOTE', \"{'proportion': 0.7, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': None}\"); total time=   0.0s\n",
      "[CV] END clf__oversampler=('distance_SMOTE', \"{'proportion': 0.7, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': None}\"); total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-28 11:22:34,216:INFO:distance_SMOTE: Running sampling via ('distance_SMOTE', \"{'proportion': 0.7, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': None}\")\n",
      "2022-09-28 11:22:34,236:INFO:distance_SMOTE: Running sampling via ('distance_SMOTE', \"{'proportion': 0.8, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': None}\")\n",
      "2022-09-28 11:22:34,258:INFO:distance_SMOTE: Running sampling via ('distance_SMOTE', \"{'proportion': 0.8, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': None}\")\n",
      "2022-09-28 11:22:34,280:INFO:distance_SMOTE: Running sampling via ('distance_SMOTE', \"{'proportion': 0.8, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': None}\")\n",
      "2022-09-28 11:22:34,302:INFO:distance_SMOTE: Running sampling via ('distance_SMOTE', \"{'proportion': 0.9, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': None}\")\n",
      "2022-09-28 11:22:34,331:INFO:distance_SMOTE: Running sampling via ('distance_SMOTE', \"{'proportion': 0.9, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': None}\")\n",
      "2022-09-28 11:22:34,352:INFO:distance_SMOTE: Running sampling via ('distance_SMOTE', \"{'proportion': 0.9, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': None}\")\n",
      "2022-09-28 11:22:34,376:INFO:distance_SMOTE: Running sampling via ('distance_SMOTE', \"{'proportion': 1.0, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': None}\")\n",
      "2022-09-28 11:22:34,401:INFO:distance_SMOTE: Running sampling via ('distance_SMOTE', \"{'proportion': 1.0, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': None}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__oversampler=('distance_SMOTE', \"{'proportion': 0.7, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': None}\"); total time=   0.0s\n",
      "[CV] END clf__oversampler=('distance_SMOTE', \"{'proportion': 0.8, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': None}\"); total time=   0.0s\n",
      "[CV] END clf__oversampler=('distance_SMOTE', \"{'proportion': 0.8, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': None}\"); total time=   0.0s\n",
      "[CV] END clf__oversampler=('distance_SMOTE', \"{'proportion': 0.8, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': None}\"); total time=   0.0s\n",
      "[CV] END clf__oversampler=('distance_SMOTE', \"{'proportion': 0.9, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': None}\"); total time=   0.0s\n",
      "[CV] END clf__oversampler=('distance_SMOTE', \"{'proportion': 0.9, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': None}\"); total time=   0.0s\n",
      "[CV] END clf__oversampler=('distance_SMOTE', \"{'proportion': 0.9, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': None}\"); total time=   0.0s\n",
      "[CV] END clf__oversampler=('distance_SMOTE', \"{'proportion': 1.0, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': None}\"); total time=   0.0s\n",
      "[CV] END clf__oversampler=('distance_SMOTE', \"{'proportion': 1.0, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': None}\"); total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-28 11:22:34,428:INFO:distance_SMOTE: Running sampling via ('distance_SMOTE', \"{'proportion': 1.0, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': None}\")\n",
      "2022-09-28 11:22:34,452:INFO:distance_SMOTE: Running sampling via ('distance_SMOTE', \"{'proportion': 1.0, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': None}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__oversampler=('distance_SMOTE', \"{'proportion': 1.0, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': None}\"); total time=   0.0s\n",
      "0.9273836765827612\n",
      "('distance_SMOTE', \"{'proportion': 1.0, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': None}\")\n",
      "Pipeline(steps=[('scale', StandardScaler()),\n",
      "                ('clf',\n",
      "                 OversamplingClassifier(classifier=GaussianNB(),\n",
      "                                        oversampler=<smote_variants._smote_variants.distance_SMOTE object at 0x000002ACDAF5BC40>))])\n"
     ]
    }
   ],
   "source": [
    "# oversampler= sv.SMOTE()\n",
    "# oversampler= sv.SMOTE_IPF()\n",
    "# oversampler= sv.SMOTE_ENN()\n",
    "oversampler= sv.SMOTE_TomekLinks()\n",
    "classifier= GaussianNB()\n",
    "# classifier= RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "model= Pipeline([\n",
    "                ('scale', StandardScaler()),\n",
    "                ('clf', sv.OversamplingClassifier(oversampler, classifier))\n",
    "            ])\n",
    "model.fit(X_train, y_train)\n",
    "param_grid= {'clf__oversampler':[sv.distance_SMOTE(proportion=0.2),\n",
    "                                 sv.distance_SMOTE(proportion=0.3),\n",
    "                                 sv.distance_SMOTE(proportion=0.4),\n",
    "                                 sv.distance_SMOTE(proportion=0.5),\n",
    "                                 sv.distance_SMOTE(proportion=0.6),\n",
    "                                 sv.distance_SMOTE(proportion=0.7),\n",
    "                                 sv.distance_SMOTE(proportion=0.8),\n",
    "                                 sv.distance_SMOTE(proportion=0.9),\n",
    "                                 sv.distance_SMOTE(proportion=1.0)]}\n",
    "\n",
    "scoring = {\"recall\": \"recall\", \"precision\": \"precision\", \"f1\" : \"f1\"}\n",
    "grid= GridSearchCV(model, param_grid= param_grid, cv= 3, n_jobs= 1, verbose= 2, scoring= scoring, refit='recall' ) #probar con lista ['f1','recall','precision']\n",
    "print(\"X_train:\" + str(len(X_train)))\n",
    "print(\"y_train:\" + str(len(y_train)))\n",
    "print(\"X_test:\" + str(len(X_test)))\n",
    "print(\"y_test:\" + str(len(y_test)))\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_score_)\n",
    "bestp = grid.best_params_['clf__oversampler']\n",
    "print(bestp)\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='analisis-smote-mejor_estimador'></a>\n",
    "## Analisis del Mejor Estimador\n",
    "1. [Inicio ▲](#Indice)\n",
    "1. [Aplicando Smote ▲](#aplicando-smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('distance_SMOTE', \"{'proportion': 1.0, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': None}\")\n",
      "<bound method BaseEstimator.get_params of GridSearchCV(cv=3,\n",
      "             estimator=Pipeline(steps=[('scale', StandardScaler()),\n",
      "                                       ('clf',\n",
      "                                        OversamplingClassifier(classifier=GaussianNB(),\n",
      "                                                               oversampler=<smote_variants._smote_variants.SMOTE_TomekLinks object at 0x000002ACDAF58C40>))]),\n",
      "             n_jobs=1,\n",
      "             param_grid={'clf__oversampler': [<smote_variants._smote_variants.distance_SMOTE object at 0x000002ACDAEC21D0>,\n",
      "                                              <smote_variants._s...\n",
      "                                              <smote_variants._smote_variants.distance_SMOTE object at 0x000002ACDAF58520>,\n",
      "                                              <smote_variants._smote_variants.distance_SMOTE object at 0x000002ACDAF5B970>,\n",
      "                                              <smote_variants._smote_variants.distance_SMOTE object at 0x000002ACDAF58B20>,\n",
      "                                              <smote_variants._smote_variants.distance_SMOTE object at 0x000002ACDAF58BB0>]},\n",
      "             refit='recall',\n",
      "             scoring={'f1': 'f1', 'precision': 'precision', 'recall': 'recall'},\n",
      "             verbose=2)>\n",
      "  proportions    Recall  Precision        F1\n",
      "0         0.2  0.790821   0.865078  0.824780\n",
      "1         0.3  0.816934   0.868471  0.841244\n",
      "2         0.4  0.845970   0.852686  0.848534\n",
      "3         0.5  0.866362   0.858246  0.861275\n",
      "4         0.6  0.883778   0.836448  0.858812\n",
      "5         0.7  0.898271   0.837873  0.866855\n",
      "6         0.8  0.904144   0.826363  0.861725\n",
      "7         0.9  0.921561   0.812206  0.862857\n",
      "8         1.0  0.927384   0.807629  0.862539\n",
      "[0 1 0 1 0 0 1 0 1 0 1 1 1 0 0 0 0 0 0 1 0 1 1 0 1 1 1 0 0 0 1 0 1 0 1 1 1\n",
      " 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 0 0 1 1 0 1 1 0 0 0 0 0\n",
      " 1 1 0 0 0 0 1 0 0 0 1 1 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 0 0 1 1 1 0 0 1 0\n",
      " 0 1 0 0 1 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 1 1 1 0 1 0 0\n",
      " 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0 1 1 0 1 0 0 0 0 1 0 1 0 1\n",
      " 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 1 1 0\n",
      " 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 1 1 0 1 0 1 1 1 0 1 1 1 1 1 0 0 1 0 1\n",
      " 1 1 0 0 0 0 1 0 0 0 0 1 0 0 1 1 1 0 0 1 1 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 1\n",
      " 0 1 1 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0 0 1 0 1 0 0 0 1\n",
      " 0 1 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 1 0 1 0 0 0 0 0 1 0 1 1 1 1 0 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 0 1 0 0\n",
      " 0 1 0 1 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0\n",
      " 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 1 1\n",
      " 1 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1\n",
      " 0 0 0 1 1 1 1 0 1 0 0 0 1 0 0 0]\n",
      "Confusion matrix\n",
      "\n",
      " [[363  34]\n",
      " [ 14 160]]\n",
      "Calculo del F1 Score es:  0.8695652173913043\n",
      "PUNTAJE MEJOR ESTIMADOR:  0.9159369527145359\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_['clf__oversampler'])\n",
    "\n",
    "datos = {'proportions' : ['0.2', '0.3', '0.4', '0.5', '0.6', '0.7', '0.8', '0.9','1.0'],\n",
    "         'Recall' : grid.cv_results_['mean_test_recall'],\n",
    "         'Precision' : grid.cv_results_['mean_test_precision'],\n",
    "         'F1' : grid.cv_results_['mean_test_f1']}\n",
    "\n",
    "df = pd.DataFrame(datos)\n",
    "\n",
    "print(grid.get_params)\n",
    "print(df)\n",
    "\n",
    "y_pred = grid.best_estimator_.predict(X_test)\n",
    "\n",
    "print(y_pred)\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print('Confusion matrix\\n\\n', cm)\n",
    "\n",
    "def calculoF1_score(cm):\n",
    "    TP = cm[1,1]\n",
    "    TN = cm[0,0]\n",
    "    FP = cm[0,1]\n",
    "    FN = cm[1,0]\n",
    "    return (2*TP)/((2*TP)+FP+FN)\n",
    "\n",
    "print('Calculo del F1 Score es: ', calculoF1_score(cm))\n",
    "print('PUNTAJE MEJOR ESTIMADOR: ' , grid.best_estimator_.score(X_test, y_test))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eabca979b0553fa6d87e9a00c352604d3b703d4afc9641643dd42376492b80f6"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
